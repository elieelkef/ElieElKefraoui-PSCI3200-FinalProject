set_rate_fb <- 0.1
set_memory <- 2
get_adstock_fb <- rep(set_rate_fb, set_memory+1) ^ c(0:set_memory)
#set adstock youtube rate
set_rate_yt <- 0.15
set_memory <- 2
get_adstock_youtube <- rep(set_rate_yt, set_memory+1) ^ c(0:set_memory)
#set adstock news rate
set_rate_news <- 0.25
set_memory <- 2
get_adstock_news <- rep(set_rate_news, set_memory+1) ^ c(0:set_memory)
#adstocked fb
ads_fb <- stats::filter(c(rep(0, set_memory), sampledf$facebook), get_adstock_fb, method="convolution")
ads_fb <- ads_fb[!is.na(ads_fb)]
#plot
plot(seq(1,length(sampledf$facebook)), sampledf$facebook, type="h",
main = "Adstocked Facebook",
xlab="Time (Weeks)", ylab="Facebook",
ylim=c(0, max(c(sampledf$facebook, ads_fb))),
frame.plot=FALSE)
lines(ads_fb, col="blue")
#adstocked youtube
ads_youtube <- stats::filter(c(rep(0, set_memory), sampledf$youtube), get_adstock_youtube, method="convolution")
ads_youtube <- ads_youtube[!is.na(ads_youtube)]
#plot
plot(seq(1,length(sampledf$youtube)), sampledf$youtube, type="h",
main = "Adstocked Youtube",
xlab="Time (Weeks)", ylab="Youtube",
ylim=c(0, max(c(sampledf$youtube, ads_youtube))),
frame.plot=FALSE)
lines(ads_youtube, col="blue")
#adstocked newpaper
ads_news <- stats::filter(c(rep(0, set_memory), sampledf$newspaper), get_adstock_news, method="convolution")
ads_news <- ads_news[!is.na(ads_news)]
#plot
plot(seq(1,length(sampledf$newspaper)), sampledf$newspaper, type="h",
main = "Adstocked Newspaper",
xlab="Time (Weeks)", ylab="Newspaper",
ylim=c(0, max(c(sampledf$newspaper, ads_news))),
frame.plot=FALSE)
lines(ads_news, col="blue")
#We are specifying sales as the dependent variable in the lm() function
mmm_1 <- lm(sampledf$sales ~ ads_youtube + ads_fb + ads_news)
summary(mmm_1)
#Check for multicollinearity using VIFs
library(mctest)
install.packages("mctest")
#We are specifying sales as the dependent variable in the lm() function
mmm_1 <- lm(sampledf$sales ~ ads_youtube + ads_fb + ads_news)
summary(mmm_1)
#Check for multicollinearity using VIFs
library(mctest)
imcdiag(mmm_1, method = "VIF")
#or use jtools
#library(jtools)
#summ(mmm_1, vifs=TRUE)
#check for heteroscedasticity
#first, plot the model out and review the siduals vs fitted plot and the Sclae-Location plot
par(mfrow=c(2,2)) # put all 4 charts into 1 page
plot(mmm_1)
#Confirm with an objective test for heteroscedasticity using Breusch Pagan test and NCV test
library(lmtest)
lmtest::bptest(mmm_1)
library(car)
car::ncvTest(mmm_1)
#h0: the variance in the model is homoskedastic (what we want).
#Both returned p-values higher than significance level 0.05,
#so we can't reject the null and can say that there are no major issues with heteros
#we can use tslm() for our regression.
#this is just  a timeseries wrapper for lm() but allows trend and seasons on the fly from the data
#https://www.rdocumentation.org/packages/forecast/versions/8.16/topics/tslm
#just specify "trend" and "season" and tslm() will automatically generate values based on the ts() object you have specified.
#fit the model
mmm_2 <- tslm(ts_sales ~ trend + season + ads_youtube + ads_fb + ads_news)
library(quantmod)
library(quantmod)
library(ggplot2)
library(forecast)
library(tseries)
library(rugarch)
library(prophet)
library(tsfknn)
#we can use tslm() for our regression.
#this is just  a timeseries wrapper for lm() but allows trend and seasons on the fly from the data
#https://www.rdocumentation.org/packages/forecast/versions/8.16/topics/tslm
#just specify "trend" and "season" and tslm() will automatically generate values based on the ts() object you have specified.
#fit the model
mmm_2 <- tslm(ts_sales ~ trend + season + ads_youtube + ads_fb + ads_news)
#Create timeseries
library(forecast)
#frequency is 52 to denote weekly as there are about 52 weeks in a year.
#ts() needs a minimum of 2 periods (52 x 2 = 104 weeks),
#our data has observations from 200 weeks so this should be sufficient
ts_sales <- ts(sampledf$sales, start = 1, frequency = 52)
#check class. should state "ts"
class(ts_sales)
#decompose to get the individual components for trends, seasonality, etc
ts_sales_comp <- decompose(ts_sales)
#plot out
plot(ts_sales_comp)
#we can use tslm() for our regression.
#this is just  a timeseries wrapper for lm() but allows trend and seasons on the fly from the data
#https://www.rdocumentation.org/packages/forecast/versions/8.16/topics/tslm
#just specify "trend" and "season" and tslm() will automatically generate values based on the ts() object you have specified.
#fit the model
mmm_2 <- tslm(ts_sales ~ trend + season + ads_youtube + ads_fb + ads_news)
summary(mmm_2)
library(igraph)
# Load the dataset from the edge list file
G <- read.graph('polbooks.txt', format='edgelist', directed=FALSE)
# Load the dataset from the edge list file
G <- read.graph('polbooks.gml', format='edgelist', directed=FALSE)
knitr::opts_chunk$set(echo = TRUE)
curve(1/(0.499 + 0.499(1+x)^0.5), from = 0, to = 0.1, xlab= "g", ylab = "bond expect return")
eq = function(x) {1/(0.499 + 0.499(1+x)^0.5}
eq = function(x){1/(0.499 + 0.499(1+x)^0.5}
eq = function(x){
1/(0.499 + 0.499((1+x)^0.5)
}
eq = function(x){
1/(0.499 + 0.499((1+x)^0.5)
curve(eq, from = 0, to = 0.1, xlab= "g", ylab = "bond expect return")
bond_er = function(x) {
1/(0.499 + 0.499((1+x)^0.5)
}
bond_er <- function(x) {
1/(0.499 + 0.499((1+x)^0.5)
}
library(tidyverse)
bond_er <- function(x) {
1/(0.499 + 0.499((1+x)^0.5)
}
bond_er <- function(x, y) {
1/(0.499 + 0.499((1+x)^y)
}
bond_er <- function(x, y){
1/(0.499 + 0.499((1+x)^y)
}
as_daily_income <- function(ghskelw) {
ghskelw / 365
}
bond_er <- function(x, y) {
1 / (0.499 + 0.499((1+x)^y)
}
bond_er <- function(x, y){
(1/(0.499 + 0.499((1+x)^y))
}
bond_er <- function(x, y) {
1 / 0.499
}
bond_er <- function(x, y) {
1 / 0.499 + 0.499x
bond_er <- function(x, y) {
1 / (0.499+0.499x)
bond_er <- function(x, y) {
((0.499 + 0.499((1+x)^y)))^-1
}
curve(bond_er(x, 0.5), from = 0, to = 0.1, xlab= "g", ylab = "bond expect return")
bond_er <- function(x, y) {
((0.499 + 0.499((1+x)^y)))^-1
}
curve(bond_er(x, 0.5), from = 0, to = 0.1, xlab= "g", ylab = "bond expect return")
bond_er <- function(x) {
((0.499 + 0.499((1+x)^0.5)))^-1
}
curve(bond_er(x), from = 0, to = 0.1, xlab= "g", ylab = "bond expect return")
curve(((0.499 + 0.499((1+x)^0.5)))^-1, from = 0, to = 0.1, xlab= "g", ylab = "bond expect return")
library("ggplot2")
eq = function(x){x*x}
ggplot(data.frame(x=c(1, 50)), aes(x=x)) +
stat_function(fun=eq)
library("ggplot2")
eq = function(x){((0.499 + 0.499((1+x)^0.5)))^-1}
ggplot(data.frame(x=c(0, .1)), aes(x=x)) +
stat_function(fun=eq)
curve(((0.499 + 0.499*((1+x)^0.5)))^-1, from = 0, to = 0.1, xlab= "g", ylab = "bond expect return")
bond_er <- function(x, y) {
((0.499 + 0.499*((1+x)^y)))^-1
}
curve(bond_er(x, 0.5), from = 0, to = 0.1, xlab= "g", ylab = "bond expect return")
curve(bond_er(x, 0.5), from = 0, to = 0.1, xlab= "g", ylab = "bond expect return")
curve(bond_er(x, 2), from = 0, to = 0.1, xlab= "g", ylab = "bond expect return")
curve(bond_er(x, 5), from = 0, to = 0.1, xlab= "g", ylab = "bond expect return")
curve(bond_er(x, 10), from = 0, to = 0.1, xlab= "g", ylab = "bond expect return")
curve(bond_er(x, 50), from = 0, to = 0.1, xlab= "g", ylab = "bond expect return")
curve(bond_er(x, 100), from = 0, to = 0.1, xlab= "g", ylab = "bond expect return")
bond_er <- function(x, y) {
((0.499 + 0.499*((1+x)^-y)))^-1
}
curve(bond_er(x, 0.5), from = 0, to = 0.1, xlab= "g", ylab = "bond expect return")
curve(bond_er(x, 2), from = 0, to = 0.1, xlab= "g", ylab = "bond expect return")
curve(bond_er(x, 5), from = 0, to = 0.1, xlab= "g", ylab = "bond expect return")
curve(bond_er(x, 10), from = 0, to = 0.1, xlab= "g", ylab = "bond expect return")
curve(bond_er(x, 50), from = 0, to = 0.1, xlab= "g", ylab = "bond expect return")
curve(bond_er(x, 100), from = 0, to = 0.1, xlab= "g", ylab = "bond expect return")
stock_er <- function(x, y) {
((1+0.5*g) / (0.499 + 0.499 * ((1 + g) ^ -y)))
}
stock_er <- function(x, y) {
((1+0.5*g) / (0.499 + 0.499 * ((1 + g) ^ -y)))
}
stock_er <- function(x, y) {
((1+0.5*x) / (0.499 + 0.499 * ((1 + x) ^ -y)))
}
curve(stock_er(x, 0.5), from = 0, to = 0.1, xlab= "g", ylab = "bond expect return")
curve(stock_er(x, 2), from = 0, to = 0.1, xlab= "g", ylab = "bond expect return")
curve(stock_er(x, 5), from = 0, to = 0.1, xlab= "g", ylab = "bond expect return")
curve(stock_er(x, 10), from = 0, to = 0.1, xlab= "g", ylab = "bond expect return")
curve(stock_er(x, 50), from = 0, to = 0.1, xlab= "g", ylab = "bond expect return")
curve(stock_er(x, 100), from = 0, to = 0.1, xlab= "g", ylab = "bond expect return")
setwd() <- ("/Users/elie/Desktop/Penn/semester 7/International Finance")
setwd("/Users/elie/Desktop/Penn/semester 7/International Finance")
PCECC96 <- read.csv("PCECC96")
setwd("/Users/elie/Desktop/Penn/semester 7/International Finance")
PCECC96 <- read.csv("PCECC96.csv")
View(PCECC96)
PCECC96 <- PCECC96%>%
mutate(PCECC96_growth = ((PCECC96 - lag(PCECC96))/lag(PCECC96
)))
sd(PCECC96$PCECC96_growth)
PCECC96_vector <- na.omit(PCECC96$PCECC96_growth)
sd(PCECC96_vector)
bond_er(0.01532, 5)
bond_er(0.01532, 2)
bond_er(0.01532, 0.5)
bond_er(0.01532, 2)
stock_er(0.01532, 2)
stock_er(0.01532, 5)
stock_er(0.01532, 10)
stock_er(0.01532, 6)
stock_er(0.01532, 7)
stock_er(0.01532, 5)
bond_er(0.01532, 6)
stock_er(0.01532, 6)
bond_er(0.01532, 2)
bond_er(0.01532, 1)
bond_er(0.01532, 2)
stock_er(0.01532, 7)
stock_er <- function(x, y) {
((1+0.5*x) / (0.499 + 0.499 * ((1 + x) ^ (1-y))))
}
curve(stock_er(x, 0.5), from = 0, to = 0.1, xlab= "g", ylab = "bond expect return")
curve(stock_er(x, 2), from = 0, to = 0.1, xlab= "g", ylab = "bond expect return")
curve(stock_er(x, 5), from = 0, to = 0.1, xlab= "g", ylab = "bond expect return")
curve(stock_er(x, 10), from = 0, to = 0.1, xlab= "g", ylab = "bond expect return")
curve(stock_er(x, 50), from = 0, to = 0.1, xlab= "g", ylab = "bond expect return")
curve(stock_er(x, 100), from = 0, to = 0.1, xlab= "g", ylab = "bond expect return")
setwd("/Users/elie/Desktop/Penn/semester 7/International Finance")
PCECC96 <- read.csv("PCECC96.csv")
PCECC96 <- PCECC96%>%
mutate(PCECC96_growth = ((PCECC96 - lag(PCECC96))/lag(PCECC96
)))
PCECC96_vector <- na.omit(PCECC96$PCECC96_growth)
sd(PCECC96_vector)
bond_er(0.01532, 2)
stock_er(0.01532, 7)
stock_er(0.01532, 10)
stock_er(0.01532, 8)
library(ggplot2)
library(ggplot2)
library(ggplot2)
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
install.packages("rlang")
install.packages("rlang")
install.packages("rlang")
install.packages("rlang")
library(ggplot2)
install.packages("rlang")
install.packages("rlang")
library(rlang)
library(ggplot2)
#library(rlang)
sessionInfo()
remove.packages(rlang)
remove.packages("rlang")
install.packages("rlang")
install.packages("rlang")
summaryInfo()
#install.packages("rlang")
sessionInfo()
sessionInfo()
sessionInfo()
sessionInfo()
knitr::opts_chunk$set(echo = TRUE)
sessionInfo()
library("rlang")
library(ggplot2)
remove.packages("rlang")
install.packages("rlang")
install.packages("rlang")
knitr::opts_chunk$set(echo = TRUE)
sessionInfo()
library(ggplot2)
install.packages("gt")
library(gt)
knitr::opts_chunk$set(echo = TRUE)
install.packages("WDI")
library(WDI)
WDI(
country = "all",
indicator = "NY.GDP.PCAP.KD",
start = 1960,
end = NULL,
extra = FALSE,
cache = NULL,
latest = NULL,
language = "en"
)
test_trial <-   WDI(
country = "all",
indicator = "NY.GDP.PCAP.KD",
start = 1960,
end = NULL,
extra = FALSE,
cache = NULL,
latest = NULL,
language = "en"
)
View(test_trial)
setwd("/Users/elie/Desktop/Penn/semester 8/psci3200/datat assignment")
preliminary_data <- read.csv("preliminary_data.csv")
setwd("/Users/elie/Desktop/Penn/semester 8/psci3200/datat assignment")
preliminary_data <- read.csv("preliminary data.csv")
View(preliminary_data)
setwd("/Users/elie/Desktop/Penn/semester 8/psci3200/datat assignment")
preliminary_data <- read.csv("preliminary data.csv")
syria_data <- read.csv("Syria data.csv")
setwd("/Users/elie/Desktop/Penn/semester 8/psci3200/datat assignment")
preliminary_data <- read.csv("preliminary data.csv")
syria_data <- read.csv("Syria data.csv")
correlation(preliminary_data[1, 20:60], preliminary_data[4, 20:60])
setwd("/Users/elie/Desktop/Penn/semester 8/psci3200/datat assignment")
preliminary_data <- read.csv("preliminary data.csv")
syria_data <- read.csv("Syria data.csv")
cor(preliminary_data[1, 20:60], preliminary_data[4, 20:60])
setwd("/Users/elie/Desktop/Penn/semester 8/psci3200/datat assignment")
df <- read.csv("preliminary data.csv")
syria_data <- read.csv("Syria data.csv")
cor(preliminary_data[1, 20:60], preliminary_data[4, 20:60])
# Correctly handling pd.NA values and ensuring conversion to float is done properly
gdp_data = df.loc[df['Series Name'] == 'GDP (constant 2015 US$)', '1988 [YR1988]':'2022 [YR2022]'].iloc[0].replace('..', pd.NA)
setwd("/Users/elie/Desktop/Penn/semester 8/psci3200/datat assignment")
df <- read.csv("preliminary data.csv")
syria_data <- read.csv("Syria data.csv")
#| include: false
#| warning: false
#| message: false
library(ggplot2)
library(readr)
library(ggdag)
library(tidyverse)
library(gt)
library(modelsummary)
# read-in data
# cdat = read_csv("https://raw.githubusercontent.com/jrspringman/psci3200-globaldev/main/workshops/cambodia_ngos/data.csv")
# dat = read_csv("https://raw.githubusercontent.com/jrspringman/psci3200-globaldev/main/workshops/aau_survey/clean_endline_did.csv" ) %>%
dat = read_csv("https://raw.githubusercontent.com/jrspringman/psci3200-globaldev/main/workshops/aau_survey/clean_endline_did.csv") %>%
# clean home region variable
mutate(q8_baseline = ifelse(q8_baseline == "Southern Nations, Nationalities, and Peoples Region", "SNNPR", q8_baseline),
q8_baseline = str_remove(q8_baseline, " Region"))
# create color palette for plotting
palette = MetBrewer::met.brewer(name = "Cross")
#| echo: false
#| warning: false
# Contacted gov't official
# Signed a petition
## Find participation measures that are based on a count
add_ecols = grep("q13_4_1$|q13_5_1$", names(dat), value = T)
dat = dat %>%
mutate(add_participation_end =  rowSums(across(add_ecols) ) )
#mutate(add_participation_end =  rowSums(across(add_ecols), na.rm = T) )
#dat$add_participation_end = dat$q13_4_1 + dat$q13_5_1
#| echo: false
#| warning: false
# Contacted gov't official
# Signed a petition
## Find participation measures that are based on a count
add_ecols = grep("q13_4_1$|q13_5_1$", names(dat), value = T)
dat = dat %>%
mutate(add_participation_end =  rowSums(across(add_ecols) ) )
#mutate(add_participation_end =  rowSums(across(add_ecols), na.rm = T) )
#dat$add_participation_end = dat$q13_4_1 + dat$q13_5_1
View(dat)
#| echo: false
#| warning: false
# participation
participate = dat %>%
select(`Additive Index` = add_participation_end,
`Signed petition` = q13_5_1,
`Contact official` = q13_4_1) %>%
drop_na() %>%
pivot_longer(everything()) %>%
group_by(name, value) %>%
tally() %>%
mutate(pct = n/sum(n))
ggplot(participate, aes(x = value, y = pct)) +
geom_col(fill = palette[9]) +
facet_wrap(vars(name), scales = "free") +
scale_y_continuous(labels = scales::percent) +
labs(y = "Percent of respondents", x = NULL,
title = "How do youth participate?",
subtitle = glue::glue("Number of respondents = {scales::comma(sum(participate$n)/7)}"))
#| echo: false
#| warning: false
## Find participation measures that are based on likert
# baseline
bcols = grep("^q13_.*_baseline$", names(dat), value = T)
dat[, paste0(bcols, "_st")] = dat[, bcols]
bcols = paste0(bcols,"_st")
# endline
ecols = grep("^q13_[1-7]_\\d$", names(dat), value = T)
dat[, paste0(ecols, "_st")] = dat[, ecols]
ecols = paste0(ecols,"_st")
# Create treatment variable
dat = dat %>% mutate(moved = case_when(q8_baseline == "Addis Ababa" ~ 0, TRUE ~ 1) )
# clean q13_
levels = c("Never", "Once or Twice", "More than twice", "More than 5 times",
"More than 10 times")
dat = dat %>%
mutate(across(c(bcols),
.fns = ~ factor(.x, levels = levels)))
# Create z-score function from Kling, Liberman, and Katz (2007)
z_score = function(x, y){
# calculate mean and sd of control group
c_mean = mean( as.numeric( unlist(x[x["moved"] == 0, y])) , na.rm = T)
c_sd = sd( as.numeric( unlist(x[x["moved"] == 0, y])) , na.rm = T)
# subtract control group mean; divide by control group SD
( as.numeric(x[, y, drop = TRUE]) - c_mean) / c_sd
}
# calculate z-scores
for (i in c(bcols, ecols)) {
dat[,i] = z_score(dat, i)
}
dat = dat %>%
rowwise() %>%
mutate( z_participation_end = mean(c_across(all_of(bcols)), na.rm = TRUE)) %>%
mutate( z_participation_base = mean(c_across(all_of(ecols)), na.rm = TRUE)) %>%
ungroup()
#| echo: false
#| warning: false
# raw
participate = dat %>%
select(`Attend meeting` = q13_1_baseline,
`Protest` = q13_2_baseline,
`NGO event` = q13_3_baseline,
`Signed petition` = q13_4_baseline,
`Contact official` = q13_5_baseline,
`Contact student representative` = q13_6_baseline,
`Contact an NGO` = q13_7_baseline) %>%
drop_na() %>%
pivot_longer(everything()) %>%
group_by(name, value) %>%
tally() %>%
mutate(pct = n/sum(n)) %>%
mutate(value = fct_relevel(value, "Never", after = Inf),
value = fct_rev(value))
ggplot(participate , aes(x = value, y = pct)) +
geom_col(fill = palette[9]) +
facet_wrap(vars(name), scales = "free", ncol = 2) +
scale_y_continuous(labels = scales::percent) +
labs(y = "Percent of respondents", x = NULL,
title = "How do youth participate?",
subtitle = glue::glue("Number of respondents = {scales::comma(sum(participate$n)/7)}")) +
scale_x_discrete(labels = scales::label_wrap(10))
#| echo: false
#| warning: false
# standardized
participate = dat %>%
select(`Z-Score Index` = z_participation_base,
`Attend meeting` = q13_1_baseline_st,
`Protest` = q13_2_baseline_st,
`NGO event` = q13_3_baseline_st,
`Signed petition` = q13_4_baseline_st,
`Contact official` = q13_5_baseline_st,
`Contact student representative` = q13_6_baseline_st,
`Contact an NGO` = q13_7_baseline_st) %>%
drop_na() %>%
pivot_longer(everything())
ggplot(participate , aes(x = value )) +
geom_histogram(aes(y = after_stat(count / sum(count))),
binwidth=.5, fill = palette[9]) +
#geom_col(fill = palette[9]) +
facet_wrap(vars(name),  ncol = 2) +
scale_y_continuous(labels = scales::percent) +
labs(y = "Percent of respondents", x = NULL,
title = "How do youth participate?")
#| echo: false
#| warning: false
regd = dat %>% select(z_participation_end, z_participation_base, moved, response_id ) %>%
pivot_longer(cols = c(z_participation_end, z_participation_base),
names_to = "time",
values_to = "z_participation") %>%
mutate(time = case_when(time == "z_participation_end" ~ 1,
TRUE ~ 0))
models <- list()
models[['Simple']] = lm(z_participation ~ moved, regd)
models[['Interaction']] = lm(z_participation ~ moved*time, regd)
modelsummary(
models,
estimate  = "{estimate}{stars} ({std.error})",
statistic = NULL,
gof_omit = 'IC|RMSE|Log|F|R2$|Std.')
setwd("/Users/elie/Desktop/Penn/semester 8/psci3200/datat assignment")
refugee_dat <- read.csv("Monthly Dataset.csv")
View(refugee_dat)
setwd("/Users/elie/Desktop/Penn/semester 8/psci3200/datat assignment")
refugee_dat <- read.csv("Monthly Dataset.csv")
library(ggplot2)
ggplot(refugee_dat, aes(x=Estimated.Refugee.Entry, y=Lebanon.Growth.Rate....)) +
geom_point()+
geom_smooth(method=lm)
